{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimport_ipynb\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_utils\u001b[39;00m\n\u001b[0;32m      9\u001b[0m pd\u001b[38;5;241m.\u001b[39mpandas\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import import_ipynb\n",
    "import data_utils\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"filtered_papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>citation</th>\n",
       "      <th>first_author</th>\n",
       "      <th>journal/book</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>create_date</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>nihms_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>relevant_paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39435445</td>\n",
       "      <td>Editorial: The operationalization of cognitive...</td>\n",
       "      <td>Winter M, Probst T, Tallon M, Schobel J, Pryss R.</td>\n",
       "      <td>Front Neurosci. 2024 Oct 7;18:1501636. doi: 10...</td>\n",
       "      <td>Winter M</td>\n",
       "      <td>Front Neurosci</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/10/22</td>\n",
       "      <td>PMC11491427</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>10.3389/fnins.2024.1501636</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39367648</td>\n",
       "      <td>An initial game-theoretic assessment of enhanc...</td>\n",
       "      <td>Fatemi MY, Lu Y, Diallo AB, Srinivasan G, Azhe...</td>\n",
       "      <td>Brief Bioinform. 2024 Sep 23;25(6):bbae476. do...</td>\n",
       "      <td>Fatemi MY</td>\n",
       "      <td>Brief Bioinform</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>PMC11452536</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>10.1093/bib/bbae476</td>\n",
       "      <td>The application of deep learning to spatial tr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39181806</td>\n",
       "      <td>Cross-modal Transfer Learning Based on an Impr...</td>\n",
       "      <td>Guo S, Chen H, Sheng X, Xiong Y, Wu M, Fischer...</td>\n",
       "      <td>Ultrasound Med Biol. 2024 Nov;50(11):1638-1645...</td>\n",
       "      <td>Guo S</td>\n",
       "      <td>Ultrasound Med Biol</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/08/24</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>10.1016/j.ultrasmedbio.2024.06.009</td>\n",
       "      <td>OBJECTIVE: Deep-learning algorithms have been ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39112796</td>\n",
       "      <td>A generalist vision-language foundation model ...</td>\n",
       "      <td>Zhang K, Zhou R, Adhikarla E, Yan Z, Liu Y, Yu...</td>\n",
       "      <td>Nat Med. 2024 Aug 7. doi: 10.1038/s41591-024-0...</td>\n",
       "      <td>Zhang K</td>\n",
       "      <td>Nat Med</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/08/07</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>10.1038/s41591-024-03185-2</td>\n",
       "      <td>Traditional biomedical artificial intelligence...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39056477</td>\n",
       "      <td>DeepComBat: A statistically motivated, hyperpa...</td>\n",
       "      <td>Hu F, Lucas A, Chen AA, Coleman K, Horng H, Ng...</td>\n",
       "      <td>Hum Brain Mapp. 2024 Aug 1;45(11):e26708. doi:...</td>\n",
       "      <td>Hu F</td>\n",
       "      <td>Hum Brain Mapp</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/07/26</td>\n",
       "      <td>PMC11273293</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>10.1002/hbm.26708</td>\n",
       "      <td>Neuroimaging data acquired using multiple scan...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "0  39435445  Editorial: The operationalization of cognitive...   \n",
       "1  39367648  An initial game-theoretic assessment of enhanc...   \n",
       "2  39181806  Cross-modal Transfer Learning Based on an Impr...   \n",
       "3  39112796  A generalist vision-language foundation model ...   \n",
       "4  39056477  DeepComBat: A statistically motivated, hyperpa...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Winter M, Probst T, Tallon M, Schobel J, Pryss R.   \n",
       "1  Fatemi MY, Lu Y, Diallo AB, Srinivasan G, Azhe...   \n",
       "2  Guo S, Chen H, Sheng X, Xiong Y, Wu M, Fischer...   \n",
       "3  Zhang K, Zhou R, Adhikarla E, Yan Z, Liu Y, Yu...   \n",
       "4  Hu F, Lucas A, Chen AA, Coleman K, Horng H, Ng...   \n",
       "\n",
       "                                            citation first_author  \\\n",
       "0  Front Neurosci. 2024 Oct 7;18:1501636. doi: 10...     Winter M   \n",
       "1  Brief Bioinform. 2024 Sep 23;25(6):bbae476. do...    Fatemi MY   \n",
       "2  Ultrasound Med Biol. 2024 Nov;50(11):1638-1645...        Guo S   \n",
       "3  Nat Med. 2024 Aug 7. doi: 10.1038/s41591-024-0...      Zhang K   \n",
       "4  Hum Brain Mapp. 2024 Aug 1;45(11):e26708. doi:...         Hu F   \n",
       "\n",
       "          journal/book  publication_year create_date        pmcid  \\\n",
       "0       Front Neurosci              2024  2024/10/22  PMC11491427   \n",
       "1      Brief Bioinform              2024  2024/10/05  PMC11452536   \n",
       "2  Ultrasound Med Biol              2024  2024/08/24  Unavailable   \n",
       "3              Nat Med              2024  2024/08/07  Unavailable   \n",
       "4       Hum Brain Mapp              2024  2024/07/26  PMC11273293   \n",
       "\n",
       "      nihms_id                                 doi  \\\n",
       "0  Unavailable          10.3389/fnins.2024.1501636   \n",
       "1  Unavailable                 10.1093/bib/bbae476   \n",
       "2  Unavailable  10.1016/j.ultrasmedbio.2024.06.009   \n",
       "3  Unavailable          10.1038/s41591-024-03185-2   \n",
       "4  Unavailable                   10.1002/hbm.26708   \n",
       "\n",
       "                                            abstract  relevant_paper  \n",
       "0                                        Unavailable            True  \n",
       "1  The application of deep learning to spatial tr...            True  \n",
       "2  OBJECTIVE: Deep-learning algorithms have been ...            True  \n",
       "3  Traditional biomedical artificial intelligence...            True  \n",
       "4  Neuroimaging data acquired using multiple scan...            True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keywords for Text mining, Computer Vision and Other\n",
    "\n",
    "text_mining_keywords = [\"natural language processing\", \"text mining\", \"nlp\", \"computational linguistics\", \"language processing\", \"text analytics\", \"textual data analysis\", \"text data analysis\", \"text analysis\", \"speech and language technology\", \"language modeling\", \"computational semantics\", \"transformer models\", \"self-attention models\", \"transformer architecture\", \"transformer\", \"attention-based neural networks\", \"transformer networks\", \"sequence-to-sequence models\", \"large language model\", \"llm\", \"transformer-based model\", \"pretrained language model\", \"generative language model\", \"foundation model\", \"state-of-the-art language model\"]\n",
    "\n",
    "computer_vision_keywords = [\"computer vision\", \"vision model\", \"image processing\", \"vision algorithms\", \"computer graphics and vision\", \"object recognition\", \"scene understanding\", \"vision transformer\", \"multimodal model\", \"multimodal neural network\", \"diffusion model\", \"generative diffusion model\", \"diffusion-based generative model\", \"continuous diffusion model\"]\n",
    "\n",
    "other_keywords = [\"virology\", \"epidemiology\", \"neural network\", \"artificial neural network\", \"machine learning model\", \"feedforward neural network\", \"neural net algorithm\", \"multilayer perceptron\", \"recurrent neural network\", \"rnn\", \"long short-term memory network\", \"lstm\", \"grnn\", \"deep learning\", \"deep neural networks\", \"generative artificial intelligence\", \"generative ai\", \"generative deep learning\", \"generative models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SentenceTransformer model\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute cosine similarity between two embeddings\n",
    "\n",
    "def compute_similarity(paper_embedding, keyword_embeddings):\n",
    "    similarities = cosine_similarity([paper_embedding], keyword_embeddings)\n",
    "    return similarities.max()  # Return the maximum similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get combined embedding of mean, min, max and then take mean of these\n",
    "\n",
    "def get_long_text_embedding(text, model, chunk_size=200):\n",
    "    # Split text into chunks\n",
    "    words = text.split()\n",
    "    chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    \n",
    "    # Generate embeddings for each chunk\n",
    "    chunk_embeddings = [model.encode(chunk) for chunk in chunks]\n",
    "    chunk_embeddings = np.vstack(chunk_embeddings)\n",
    "    \n",
    "    # Calculate mean, max, and min embeddings\n",
    "    mean_embedding = np.mean(chunk_embeddings, axis=0)\n",
    "    max_embedding = np.max(chunk_embeddings, axis=0)\n",
    "    min_embedding = np.min(chunk_embeddings, axis=0)\n",
    "    \n",
    "    # Take the mean of [mean_embedding, max_embedding, min_embedding]\n",
    "    combined_embedding = np.mean([mean_embedding, max_embedding, min_embedding], axis=0)\n",
    "    return combined_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each set of keywords\n",
    "\n",
    "text_mining_embeddings = model.encode(text_mining_keywords, convert_to_tensor=True)\n",
    "\n",
    "computer_vision_embeddings = model.encode(computer_vision_keywords, convert_to_tensor=True)\n",
    "\n",
    "other_embeddings = model.encode(other_keywords, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify each paper\n",
    "def classify_paper(row):\n",
    "    # Combine title and abstract\n",
    "    text = row['title'] + \" \" + row['abstract']\n",
    "    \n",
    "    # Removing newline escape sequences\n",
    "    text = re.sub(r'[\\n]', ' ', text)\n",
    "\n",
    "    # Get embedding for long text with chunking\n",
    "    paper_embedding = get_long_text_embedding(text, model)\n",
    "\n",
    "    # Calculate similarity with each keyword category\n",
    "    text_mining_similarity = util.cos_sim(paper_embedding, text_mining_embeddings).max().item()\n",
    "    computer_vision_similarity = util.cos_sim(paper_embedding, computer_vision_embeddings).max().item()\n",
    "    other_similarity = util.cos_sim(paper_embedding, other_embeddings).max().item()\n",
    "\n",
    "    # Determine classification based on highest similarity score\n",
    "    if text_mining_similarity > 0.3 and computer_vision_similarity > 0.3:\n",
    "        return \"both\"\n",
    "    elif text_mining_similarity > computer_vision_similarity and text_mining_similarity > other_similarity and text_mining_similarity > 0.4:\n",
    "        return \"text mining\"\n",
    "    elif computer_vision_similarity > text_mining_similarity and computer_vision_similarity > other_similarity and computer_vision_similarity > 0.4:\n",
    "        return \"computer vision\"\n",
    "    elif other_similarity > text_mining_similarity and other_similarity > computer_vision_similarity and other_similarity > 0.4:\n",
    "        return \"other\"\n",
    "    else:\n",
    "        return \"other\"  # Default to \"other\" if no category exceeds the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the classification function to each paper\n",
    "\n",
    "dataset['Method_Type'] = dataset.apply(classify_paper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Method_Type\n",
       "other              2801\n",
       "text mining         549\n",
       "both                179\n",
       "computer vision     127\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Method_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Editorial: The operationalization of cognitive...   \n",
      "1  An initial game-theoretic assessment of enhanc...   \n",
      "2  Cross-modal Transfer Learning Based on an Impr...   \n",
      "3  A generalist vision-language foundation model ...   \n",
      "4  DeepComBat: A statistically motivated, hyperpa...   \n",
      "\n",
      "                                            abstract      Method_Type  \n",
      "0                                        Unavailable  computer vision  \n",
      "1  The application of deep learning to spatial tr...            other  \n",
      "2  OBJECTIVE: Deep-learning algorithms have been ...             both  \n",
      "3  Traditional biomedical artificial intelligence...            other  \n",
      "4  Neuroimaging data acquired using multiple scan...            other  \n"
     ]
    }
   ],
   "source": [
    "print(dataset[['title', 'abstract', 'Method_Type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Method_Type\n",
       "other              2801\n",
       "text mining         549\n",
       "both                179\n",
       "computer vision     127\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Method_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3656, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered papers\n",
    "\n",
    "dataset.to_csv('methodType_classified_papers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
